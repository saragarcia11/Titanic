---
title: "Borrador_markdown"
output:
  pdf_document: default
  html_document:
    df_print: paged
  word_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

```{r}
# Empezamos por importar el dataset 
Data_Original <- read.csv('train.csv', stringsAsFactors = FALSE, header = TRUE)
```

```{r}
# Observamos los primeros resultados del dataset con la función head()
head(Data_Original)
```


```{r}
# Observamos  los tipos de variables que tenemos y sus valores
str(Data_Original)
```
```{r}
# Análisis estadístico de la distribución  de los valores
summary(Data_Original)
```
```{r}
# Eliminamos del dataframe las columnas que no nos interesan para el análisis: Ticket, Cabin y Embarked
borrar <- c("Ticket","Cabin", "Embarked")
df <- Data_Original[ , !(names(Data_Original) %in% borrar)]

# Comprobamos que la eliminación ha sido correcta
head(df, n=5)
```
```{r}
# Para continuar con el análisis, comprobamos la presencia de valores NA
colSums(is.na(Data_Original))
```
```{r}
# Vemos que tenemos valores vacíos en la variable Age; los reemplazamos por la media de la edad
df$Age[is.na(df$Age)] <- mean(df$Age, na.rm=T)
``` 

```{r}
# Comprobamos que no quedan valores vacios en las variables elegidas
colSums(df=="")
```
```{r, echo=FALSE}

# Para acabar de limpiar la variable Age, redondeamos sus valores para tener solo números enteros.

df$Age <- as.integer(df$Age)

typeof(df$Age)

```
```{r, echo=FALSE}
# Pasamos ahora a identificar outliers haciendo uso de boxplot
par(mfrow=c(1,2))
boxplot(df$SibSp)
boxplot(df$Parch)

# Con estas dos variables se identifican ciertos registros como outliers que no son en verdad valores anómalos. Aunque la mayor parte de la gente tuviese 'pocos' familiares a bordo, es factible que tengan 8 o 6, que son los valores identificados como outliers. Por tanto, ignoramos de momento esta consideración.
```
```{r, echo=FALSE}

boxplot(df$Fare)

# En este caso se identifican muchos valores anómalos, pero el único que es en realidad un outlier es el mayor (con valor 512.33). Existen tres tipos de billetes -clase 1, 2 o 3- y, en función de la clase, el precio es mayor o menor generalmente. Como no hay la misma cantidad de billetes de cada una de las tres clases, se identifican como valores anómalos precios más elevados que, aunque destaquen en comparación con los más bajos, son razonables para el precio de billetes de primera clase. 
```
```{r, echo=FALSE}
# Para tratar el outlier directamente lo eliminamos del total del registro:
df2 <- subset(df, Fare!=512.3292)
# Comprobamos visualmente la eliminación dle outlier
boxplot(df2$Fare)
```
```{r}
# Para acabar de limpiar la variable 'Fare', redondeamos todos sus registros a dos decimales
df2$Fare <- round(df2$Fare, 2)
```

```{r}
# Comenzamos la factorización
# Primero, comprobamos qué variables son las que debemos binarizar
apply(df2, 2, function(x) length(unique(x)))
```
```{r}
# Y binarizamos la variable 'sex', para registrarla en vez de como 'male' y 'female', como (0,1)

df2 <- transform(df2, Sex = ifelse(Sex== "male", 0, 1))

# Después de los cambios, analizamos la nueva estructura del conjunto de datos
str(df2)
```
```{r}
# El siguiente paso es crear una nueva variable ('Fam') a partir de la combinación de las variables SibSp y Parch. Esta variable nos indica si el sujeto tiene (1) o no tiene (0) familia.
df3 <- transform(df2, Fam = ifelse(SibSp==0 & Parch ==0, 0, 1))

# Comprobamos que la variable 'Fam' se ha creado correctamente, tomando valor 1 si el sujeto tiene algún familiar (si SibSp o Parch es distinto de cero) y valor 0 si no tienen ninguno (SibSp y Parch son iguales a cero).

summary(df3$Fam)
unique(df3$Fam[df3$SibSp==0 & df3$Parch == 0])
``` 
```{r}
# Habiendo comprobado que hemos creado con éxito la variable Fam, vamos a eliminar las variables 'SibSp' y 'Parch', ya que el contenido de interés analítico en este caso se encuentra recogido en la nueva variable 'Fam'.

borrar <- c("SibSp","Parch")
df_final <- df3[ , !(names(df3) %in% borrar)]

# Y comprobamos que se han borrado correctamente:

head(df_final)
```


```{r}

# Antes de exportar nuestros datos, vamos a factorizar las variables que lo requieran para evitar futuros conflictos.

str(df_final)

```
```{r}
# Vemos que las variables que no son leídas como factores son 'Survived', 'Pclass', 'Sex' y 'Fam', las factorizamos y nuestra base de datos queda lista para el análisis

cols<-c("Survived", "Pclass", "Sex", "Fam")
for (i in cols){
  df_final[,i] <- as.factor(df_final[,i])
}

str(df_final)

```
```{r}

write.csv(df_final, "Data Final.csv", row.names=FALSE)

```

```{r}

# Antes de comenzar con el análisis, vamos a observar cómo se comportan las variables finales con las que trabajaremos. Usaremos primero histogramas para hacernos una primera idea.

par(mfrow=c(1,2))
hist(df_final$Age)
hist(df_final$Fare)
```
```{r}

# De la representación anterior, vemos que la variable 'Fare' (precio del billete) requeriría de una escala logarítmica para poder observar mejor cómo se comportan sus registros.

hist(log(df_final$Fare))
```



```{r}
# Hacemos una primera representación de las correlaciones entre variables para ir haciéndonos una idea de cómo se comportan los registros que tenemos.

vars <- df_final[, c("Survived", "Pclass", "Sex", "Age", "Fare", "Fam")]

```

```{r}
#Análisis de la normalidad de Age
par(mfrow=c(3,1))
qqnorm(df_final$Age);qqline(df_final$Age,col=2)
qqnorm(df_final$Fare);qqline(df_final$Fare,col=2)

```
```{r}

# install.packages("GGally")

library(GGally)
library(ggplot2)
```

```{r}

ggpairs(vars, lower = list(continuous="smooth"), diag = list(continuous="barDiag"), axisLabels = "none")
```
```{r}

# Graficamos algunas variables en función de survived, para observar tendencias en las relaciones y guiarnos para la construcción de nuestros análisis

library(ggplot2)
# install.packages("dplyr")
library(dplyr)
filas=dim(df_final)

# Empezamos por ver la relación entre el género y la supervivencia (Sex-Survival)

ggplot(data=df_final[1:filas,],aes(x=Sex,fill=Survived))+geom_bar()
```
```{r}

# Y graficamos también la supervivencia en función de la edad

ggplot(data = df_final[!(is.na(df_final[1:filas,]$Age)),],aes(x=Age,fill=Survived))+geom_histogram(binwidth =3)

```



```{r}

# Probamos a continuación a graficar Survival en función de Pclass

ggplot(data = df_final[1:filas,],aes(x=Pclass,fill=Survived))+geom_bar(position="fill")+ylab("Frecuencia")

```

```{r}

# Obtenemos, además, una matriz de porcentajes de freccuencia. Vemos que la probabilidad de sobrevivir si el billete es de primera clase es de 62.44%, si es de segunda clase 47.28%, y si es de tercera clase 24,24%.

t<-table(df_final[1:filas,]$Pclass, df_final[1:filas,]$Survived)
for (i in 1:dim(t)[1]){
    t[i,]<-t[i,]/sum(t[i,])*100
}

t
```

```{r}

# Comenzamos con el análisis de nuestro dataset, compuesto de tres partes:
# 1 - Correlación + regresión simple: ¿Existe una correlación entre pagar más por el billete y aumentar tu probabilidad de sobrevivir? ¿Cuánto afecta el precio del billete a la probabilidad de sobrevivir?
# 2 - Regresión: ¿Afectaron las características identitarias de una persona (su edad, género, clase y si tiene o no familia) a su probabilidad de sobrevivir?
# 3 - Métodos de asociación. Dadas las diferentes combinaciones de valores para cada registro, ¿es posible establecer unas reglas en forma de condicional que representen la probabilidad de diferentes darse determinadas combinaciones de eventos?


# CORRELACIÓN

# Cuando uno paga más por un billete de primera, puede pensar que paga no solo por lujo sino por un aumeno de la seguridad. Comprobamos si efectivamente existe una correlación entre el precio del billete (Fare) y la supervivencia (Survived)

# Con este fin, registramos la variable Survived como numérica 

df_final$Survived_numeric <- as.numeric(df_final$Survived)

```

```{r}
var.cor <- select(df_final, Survived_numeric, Fare)
correlacion1 <- cor(var.cor, method = "pearson")
# install.packages("corrplot")
library(corrplot)
corrplot(correlacion1, method = "number", type = "upper")

```
```{r}

# Realizamos la regresión simple entre Fare y Survived.

regresion_simple <- glm(formula = Survived~Fare, data = df_final, family = binomial)

summary(regresion_simple)

```


```{r}

# Usamos cross-validation para comprobar la efectividad de nuestra regresión.

# install.packages("caret")
library("lattice")
library("caret")
library("ggplot2")

data_ctrl <- trainControl(method = "cv", number = 5)

regresion_simple_cross <- train(Survived ~ Fare,   # model to fit
                     data = df_final,                        
                     trControl = data_ctrl,             # folds
                     method = "glm",     # specifying regression model
                     family=binomial(), # specifying regression model
                     na.action = na.pass)

summary(regresion_simple_cross)

# Comprobamos que tanto los coeficientes como el valor de AIC es igual en los dos modelos, y por tanto mantenemos nuestro modelo original.

```



```{r}

# install.packages("pROC")

library(pROC)

probabilidad_bajo=predict(regresion_simple, df_final, type="response")
r=roc(df_final$Survived, probabilidad_bajo, data = df_final)

plot(r)
```
```{r}

auc(r)

# Como el área bajo la curva está entre 0.6 y 0.8, podemos considerar que el modelo discrimina de manera adecuada.

```

```{r}

# Representamos gráficamente nuestros resultados sobre la relación entre 'Fare' y 'Survived' mediante un 'ridgeline plot'

# install.packages("ggridges")
library(ggridges)
library(ggplot2)
 

ggplot(df_final, aes(x = Fare, y = Survived, fill = Survived)) +
  geom_density_ridges() +
  theme_ridges() + 
  theme(legend.position = "none")


```
```{r}

library(ggplot2)

p <- ggplot(df_final, aes(x=Fare, y=Survived, fill=Fare)) +   
  geom_violin()
p
```

```{r}

# PARTE 2 - Realizamos una regresión logística múltiple para ver de qué manera los rasgos identitarios de la persona afectan a sus probabilidades de supervivencia. Lo evaluamos con las variables: sex, age, pclass (proxy de la clase social) y Fam.

regresion_multiple <- glm(formula = Survived~Age+Sex+Pclass+Fam, data = df_final, family = binomial)
summary(regresion_multiple)

```

```{r}
# Realizamos ahora la comprobación con crossed-validation

regresion_multiple_cross <- train(Survived ~ Age+Sex+Pclass+Fam,   # model to fit
                     data = df_final,                        
                     trControl = data_ctrl,             # folds
                     method = "glm",     # specifying regression model
                     family=binomial(), # specifying regression model
                     na.action = na.pass)

summary(regresion_multiple_cross)

# No varían los estimadores, AIC ni p-value, mantenemos la regresión original
```

```{r}

library(pROC)

probabilidad_bajo=predict(regresion_multiple, df_final, type="response")
r=roc(df_final$Survived, probabilidad_bajo, data = df_final)

plot(r)

```
```{r}

auc(r)

# Como el área bajo la curva está entre 0.8 y 0.9, se estima que el modelo discrimina de forma excelente.

# Vemos que la variable que no afecta de forma significativa es Fam, por lo tanto vamos a realizar de nuevo la regresión sin considerar esta variable para ver si podemos ajustar aún más nuestros resultados

```


```{r}

regresion_multiple2 <- glm(formula = Survived~Age+Sex+Pclass, data = df_final, family = binomial)
summary(regresion_multiple2)

```

```{r}

library(pROC)

probabilidad_bajo=predict(regresion_multiple2, df_final, type="response")
r=roc(df_final$Survived, probabilidad_bajo, data = df_final)

plot(r)

```

```{r}

auc(r)

# Vemos que el modelo no mejora significativamente 

```

```{r}

# Para representar el valor de los estimadores, creamos una nueva base de datos con el valor de los estimadores y el nombre de las variables.

variables <- c("Age", "Sex1", "Pclass2", "Pclass3", "Fam")
estimadores <- c(0.03374, 2.63908, 1.09509, 2.31242, 0.07749)

df_grafico <- data.frame(variables, estimadores)

head(df_grafico)

```

```{r}

# install.packages("wordcloud2")

library(wordcloud2)

wordcloud2(data=df_grafico, size=1.6)
```

 
```{r}
# PARTE 3 MÉTODOS DE ASOCIACIÓN

# En esta tercera parte vamos a obtener reglas de asociacion a partir de una selección de variables categóricas del dataset. 
# Dichas reglas nos ayudarán a comprender cómo la información del data set se relaciona entre si.

#install.packages("arules")
library(arules)

df_final1<- select(df_final, "Fam", "Sex", "Pclass", "Survived")
titanic_rules <- apriori(df_final1, parameter = list(support = 0.01, confidence = 0.5))
inspect(head(sort(titanic_rules, by = "confidence"), 5))

# Como vemos se ha generado un set de reglas con diferente soporte, confianza y lift.

# El soporte indica cuantas veces se han encontrado las reglas {lsh => rhs} en el dataset, cuanto más alto mejor. 
# La confianza habla de la probabilidad de que {rhs} se de en función de {lhs}. 
# El lift es un parámetro que nos indica cuánto de aleatoriedad hay en las reglas. Un lift de 1 o menos es que las reglas son 
# completamente fruto del azar.

```

```{r}
# Representación visual
# install.packages("arulesViz")

library(arulesViz)

# Creamos un subconjunto de 5 reglas de entre todas las reglas posibles.
subrules <- head(sort(titanic_rules, by = "confidence"), 5)
plot(subrules, method="graph")
```
```{r}
plot(subrules, method = "grouped", control = list(k = 5))
```
```{r}
plot(subrules, method="paracoord",  control=list(alpha=.5, reorder=FALSE))
```
